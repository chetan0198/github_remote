{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97b72cf-08af-480d-8e1d-e3460c3f972a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas\n"
     ]
    }
   ],
   "source": [
    "print('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9f820c-2a92-450b-8aca-e0dcb3505386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7ffb833b4370>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482de841-37bd-46f4-83a3-258859ab737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to CSV file: test12/file.csv\n"
     ]
    }
   ],
   "source": [
    "# Create pyspark df\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rawdata=[{'timestamp_key': '2024-01-16 11:56:00.252982', 'symbol': 'MSFT', 'price': 959.1, 'volume': 528074}]\n",
    "pydf=spark.createDataFrame(data=rawdata)\n",
    "# pydf.show()\n",
    "\n",
    "df=pydf.toPandas()\n",
    "# df.head()\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'test12/file.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(\"DataFrame saved to CSV file:\", csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b01a17f-e2f4-406d-8758-181679674e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended successfully2.\n"
     ]
    }
   ],
   "source": [
    "# Append Pandas DataFrame to Existing CSV File\n",
    "# importing pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# data of Player and their performance\n",
    "data = [{'timestamp_key': '2024-01-16 11:56:00.252982', 'symbol': 'MSFT22', 'price': 959.1, 'volume': 528074}]\n",
    "\n",
    "pydf=spark.createDataFrame(data=data)\n",
    "\n",
    "df=pydf.toPandas()\n",
    "\n",
    "df.to_csv('test12/file.csv', mode='a', index=False, header=False)\n",
    "\n",
    "# print message\n",
    "print(\"Data appended successfully2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a36093-2f9d-40e7-8b25-3b21f50078b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to CSV file: test11/file.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your Pandas DataFrame\n",
    "data = {\n",
    "    'timestamp_key': ['2024-01-15 17:33:19.805397', '2024-01-15 18:45:30.123456'],\n",
    "    'symbol': ['AAPL', 'GOOGL'],\n",
    "    'price': [371.85, 2000.0],\n",
    "    'volume': [701860, 500]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'test11/file.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(\"DataFrame saved to CSV file:\", csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
